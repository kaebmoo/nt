import pandas as pd
import numpy as np
from sklearn.ensemble import IsolationForest

class FullAuditDetector:
    def __init__(self, df):
        self.df = df.copy()

    # ---------------------------------------------------------
    # ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 1: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (Time Series)
    # "Product A ‡∏°‡∏µ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ö‡πâ‡∏≤‡∏á ‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡∏≠‡∏î‡∏µ‡∏ï‡∏à‡∏ô‡∏ñ‡∏∂‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô"
    # ---------------------------------------------------------
    def check_time_series_all_months(self, target_col, date_col, dimension_cols, window=3):
        print(f"üîç ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£ (Rolling Window {window} ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô)...")
        
        results = []
        
        # ‡∏à‡∏±‡∏î‡∏Å‡∏•‡∏∏‡πà‡∏°‡∏ï‡∏≤‡∏° Product/Service (Dimension)
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á ID ‡∏ä‡∏±‡πà‡∏ß‡∏Ñ‡∏£‡∏≤‡∏ß‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ß‡∏ô‡∏•‡∏π‡∏õ
        self.df['TEMP_ID'] = self.df[dimension_cols].apply(lambda x: '|'.join(x.astype(str)), axis=1)
        
        for item_id, group_data in self.df.groupby('TEMP_ID'):
            # ‡πÄ‡∏£‡∏µ‡∏¢‡∏á‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡πÉ‡∏´‡πâ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
            group_data = group_data.sort_values(date_col)
            
            # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ï‡∏£‡∏ß‡∏à‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏±‡πâ‡∏á‡πÅ‡∏ï‡πà‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ó‡∏µ‡πà window + 1)
            values = group_data[target_col].values
            dates = group_data[date_col].values
            
            for i in range(window, len(group_data)):
                current_val = values[i]
                current_date = dates[i]
                
                # ‡∏î‡∏∂‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏¢‡πâ‡∏≠‡∏ô‡∏´‡∏•‡∏±‡∏á‡∏ï‡∏≤‡∏° window ‡∏ó‡∏µ‡πà‡∏Å‡∏≥‡∏´‡∏ô‡∏î (‡πÄ‡∏ä‡πà‡∏ô 3 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤)
                history = values[i-window : i]
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏î‡πâ‡∏ß‡∏¢ IQR (‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏¥‡∏°‡πÅ‡∏ï‡πà‡∏ó‡∏≥‡πÄ‡∏õ‡πá‡∏ô Loop)
                status = self._detect_iqr(current_val, history)
                
                if status != 'Normal':
                    row_result = group_data.iloc[i].to_dict()
                    row_result['ANOMALY_TYPE'] = 'Time_Series' # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
                    row_result['ISSUE'] = status
                    row_result['COMPARED_WITH'] = f"Avg Past {window} Months: {np.mean(history):.2f}"
                    results.append(row_result)
                    
        return pd.DataFrame(results)

    # ---------------------------------------------------------
    # ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà 2: ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô (Peer Group)
    # "‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏ô‡∏µ‡πâ ‡∏°‡∏µ‡∏´‡∏ô‡πà‡∏ß‡∏¢‡∏á‡∏≤‡∏ô‡πÑ‡∏´‡∏ô‡∏à‡πà‡∏≤‡∏¢‡∏Ñ‡πà‡∏≤‡∏ã‡πà‡∏≠‡∏°‡πÅ‡∏û‡∏á‡∏Å‡∏ß‡πà‡∏≤‡∏ä‡∏≤‡∏ß‡∏ö‡πâ‡∏≤‡∏ô"
    # ---------------------------------------------------------
    def check_peer_group(self, target_col, date_col, group_by_cols):
        print(f"üë• ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏•‡∏∏‡πà‡∏° (Peer Comparison)...")
        
        results = []
        
        # ‡∏ß‡∏ô‡∏•‡∏π‡∏õ‡∏ó‡∏µ‡∏•‡∏∞‡πÄ‡∏î‡∏∑‡∏≠‡∏ô (‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡πÄ‡∏£‡∏≤‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô‡πÉ‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô)
        unique_months = self.df[date_col].unique()
        
        for month in unique_months:
            month_data = self.df[self.df[date_col] == month].copy()
            
            if len(month_data) < 3: continue # ‡∏ñ‡πâ‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ô‡πâ‡∏≠‡∏¢‡πÑ‡∏õ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ
            
            # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (Z-Score ‡∏´‡∏£‡∏∑‡∏≠ Isolation Forest)
            values = month_data[target_col].values.reshape(-1, 1)
            
            # ‡πÉ‡∏ä‡πâ Isolation Forest (‡πÄ‡∏´‡∏°‡∏≤‡∏∞‡∏Å‡∏±‡∏ö‡∏´‡∏≤‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡πÅ‡∏õ‡∏•‡∏Å‡πÅ‡∏¢‡∏Å‡∏à‡∏≤‡∏Å‡∏Å‡∏•‡∏∏‡πà‡∏°)
            clf = IsolationForest(contamination=0.05, random_state=42)
            preds = clf.fit_predict(values) # -1 ‡∏Ñ‡∏∑‡∏≠‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
            
            # ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞‡πÉ‡∏ä‡πâ Z-Score ‡∏á‡πà‡∏≤‡∏¢‡πÜ
            mean_val = np.mean(month_data[target_col])
            std_val = np.std(month_data[target_col])
            
            # ‡∏´‡∏≤‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ó‡∏µ‡πà‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥
            anomalies = month_data[preds == -1]
            
            for _, row in anomalies.iterrows():
                # Double check ‡∏î‡πâ‡∏ß‡∏¢ Z-Score ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ä‡∏±‡∏ß‡∏£‡πå‡∏ß‡πà‡∏≤‡∏™‡∏π‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡πà‡∏≥
                z_score = (row[target_col] - mean_val) / std_val if std_val > 0 else 0
                
                issue_type = "High_vs_Peers" if row[target_col] > mean_val else "Low_vs_Peers"
                
                row_result = row.to_dict()
                row_result['ANOMALY_TYPE'] = 'Peer_Group' # ‡∏£‡∏∞‡∏ö‡∏∏‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô
                row_result['ISSUE'] = issue_type
                row_result['COMPARED_WITH'] = f"Group Avg: {mean_val:.2f} (Z={z_score:.2f})"
                results.append(row_result)
                
        return pd.DataFrame(results)

    def _detect_iqr(self, current, history):
        """‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì IQR ‡πÄ‡∏î‡∏¥‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì"""
        # ‡∏Å‡∏£‡∏≠‡∏á‡∏Ñ‡πà‡∏≤ 0 ‡∏´‡∏£‡∏∑‡∏≠‡∏ï‡∏¥‡∏î‡∏•‡∏ö‡∏≠‡∏≠‡∏Å‡∏Å‡πà‡∏≠‡∏ô‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì Baseline (‡∏ï‡∏≤‡∏°‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£)
        history_clean = history[history > 0]
        if len(history_clean) == 0: return "Normal"
        
        Q1 = np.percentile(history_clean, 25)
        Q3 = np.percentile(history_clean, 75)
        IQR = Q3 - Q1
        
        if IQR == 0: return "Normal"
        
        k = 1.5
        upper = Q3 + (k * IQR)
        lower = Q1 - (k * IQR)
        
        if current > upper: return "High_Spike"
        # ‡∏ñ‡πâ‡∏≤‡∏ï‡πà‡∏≥‡∏Å‡∏ß‡πà‡∏≤ 0 ‡∏õ‡∏Å‡∏ï‡∏¥ IQR ‡∏à‡∏∞‡∏°‡∏≠‡∏á‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô Low ‡πÅ‡∏ï‡πà‡∏ö‡∏±‡∏ç‡∏ä‡∏µ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏°‡∏≠‡∏á‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏õ‡∏Å‡∏ï‡∏¥
        # ‡∏Ñ‡∏∏‡∏ì‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏õ‡∏£‡∏±‡∏ö Logic ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡πÑ‡∏î‡πâ
        if current < lower and current > 0: return "Low_Drop" 
        
        return "Normal"

# =========================================
# ‡∏ß‡∏¥‡∏ò‡∏µ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô
# =========================================
#‡∏™‡∏°‡∏°‡∏ï‡∏¥ df ‡∏°‡∏µ‡∏Ñ‡∏≠‡∏•‡∏±‡∏°‡∏ô‡πå: MONTH, DEPT_NAME, EXPENSE_TYPE, AMOUNT

# detector = FullAuditDetector(df)

# 1. ‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤ "‡πÅ‡∏ú‡∏ô‡∏Å IT" ‡πÄ‡∏Ñ‡∏¢‡∏°‡∏µ‡∏Ñ‡πà‡∏≤‡∏ã‡πà‡∏≠‡∏°‡∏Ñ‡∏≠‡∏°‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡πÑ‡∏´‡∏ô‡∏û‡∏∏‡πà‡∏á‡∏ú‡∏¥‡∏î‡∏õ‡∏Å‡∏ï‡∏¥‡∏ö‡πâ‡∏≤‡∏á (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á)
# ts_anomalies = detector.check_time_series_all_months(
#     target_col='AMOUNT', 
#     date_col='MONTH', 
#     dimension_cols=['DEPT_NAME', 'EXPENSE_TYPE'],
#     window=6 # ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Å‡∏±‡∏ö 6 ‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤
# )

# 2. ‡∏≠‡∏¢‡∏≤‡∏Å‡∏£‡∏π‡πâ‡∏ß‡πà‡∏≤ "‡πÄ‡∏î‡∏∑‡∏≠‡∏ô ‡∏Å.‡∏¢." ‡πÅ‡∏ú‡∏ô‡∏Å‡πÑ‡∏´‡∏ô‡πÄ‡∏ö‡∏¥‡∏Å‡∏Ñ‡πà‡∏≤‡πÄ‡∏î‡∏¥‡∏ô‡∏ó‡∏≤‡∏á‡πÄ‡∏¢‡∏≠‡∏∞‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ú‡∏ô‡∏Å‡∏≠‡∏∑‡πà‡∏ô (‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ô)
# peer_anomalies = detector.check_peer_group(
#     target_col='AMOUNT',
#     date_col='MONTH',
#     group_by_cols=['EXPENSE_TYPE'] # ‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÉ‡∏ô‡∏´‡∏°‡∏ß‡∏î‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ô
# )

# 3. ‡πÄ‡∏≠‡∏≤‡∏°‡∏≤‡∏£‡∏ß‡∏°‡∏Å‡∏±‡∏ô‡∏î‡∏π
# all_issues = pd.concat([ts_anomalies, peer_anomalies])
# print(all_issues)